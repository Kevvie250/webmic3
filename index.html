<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Phone Call Recorder</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            height: 100vh;
            padding: 20px;
        }
        .container {
            max-width: 600px;
            margin: 0 auto;
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
            padding: 30px;
        }
        h1 {
            color: #333;
            margin-bottom: 30px;
            text-align: center;
        }
        .section {
            margin-bottom: 25px;
            padding: 20px;
            background: #f8f9fa;
            border-radius: 10px;
        }
        .section-title {
            font-size: 14px;
            font-weight: 600;
            color: #666;
            text-transform: uppercase;
            letter-spacing: 1px;
            margin-bottom: 15px;
        }
        .audio-meter {
            height: 40px;
            background: #e0e0e0;
            border-radius: 20px;
            overflow: hidden;
            position: relative;
            margin-bottom: 10px;
            border: 2px solid #ccc;
        }
        .audio-level {
            height: 100%;
            background: linear-gradient(90deg, #4ade80 0%, #fbbf24 70%, #ef4444 100%);
            border-radius: 20px;
            transition: width 0.1s ease-out;
            width: 0%;
        }
        .btn {
            width: 100%;
            padding: 15px;
            border: none;
            border-radius: 10px;
            font-size: 16px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s;
            text-transform: uppercase;
            letter-spacing: 1px;
            margin-top: 10px;
        }
        .btn-record {
            background: #ef4444;
            color: white;
        }
        .btn-record.recording {
            background: #991b1b;
            animation: pulse 1.5s infinite;
        }
        @keyframes pulse {
            0% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.7); }
            70% { box-shadow: 0 0 0 10px rgba(239, 68, 68, 0); }
            100% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0); }
        }
        .btn-play {
            background: #10b981;
            color: white;
        }
        .btn-transcribe {
            background: #8b5cf6;
            color: white;
        }
        .status {
            padding: 15px;
            background: #f0f9ff;
            border-left: 4px solid #3b82f6;
            border-radius: 5px;
            font-size: 14px;
            color: #1e40af;
            margin-top: 20px;
        }
        .status.error {
            background: #fef2f2;
            border-left-color: #ef4444;
            color: #991b1b;
        }
        .status.success {
            background: #f0fdf4;
            border-left-color: #10b981;
            color: #166534;
        }
        input[type="text"] {
            width: 100%;
            padding: 10px;
            border: 2px solid #e0e0e0;
            border-radius: 8px;
            font-size: 14px;
            margin-bottom: 10px;
        }
        .recording-indicator {
            display: none;
            align-items: center;
            gap: 10px;
            padding: 10px;
            background: #fee2e2;
            border-radius: 8px;
            margin-top: 15px;
        }
        .recording-indicator.active {
            display: flex;
        }
        .recording-dot {
            width: 12px;
            height: 12px;
            background: #ef4444;
            border-radius: 50%;
            animation: blink 1s infinite;
        }
        @keyframes blink {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.3; }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üéôÔ∏è Phone Call Recorder</h1>
        
        <div class="section">
            <div class="section-title">Audio Input Level</div>
            <div style="font-size: 12px; color: #666; margin-bottom: 10px;">Configure virtual audio cable as default input in Windows. Level shows when audio is flowing:</div>
            <div class="audio-meter">
                <div class="audio-level" id="inputLevel"></div>
            </div>
        </div>
        
        <div class="section">
            <div class="section-title">Recording</div>
            <button class="btn btn-record" id="recordBtn" onclick="toggleRecording()">
                Start Recording
            </button>
            <div class="recording-indicator" id="recordingIndicator">
                <div class="recording-dot"></div>
                <span>Recording...</span>
                <span id="recordingTimer">00:00</span>
            </div>
        </div>
        
        <div class="section">
            <div class="section-title">Playback</div>
            <input type="text" id="audioUrl" placeholder="Paste ElevenLabs URL (or leave empty to play last recording)">
            <button class="btn btn-play" onclick="playAudio()">Play Audio</button>
        </div>
        
        <div class="section">
            <div class="section-title">Transcription</div>
            <button class="btn btn-transcribe" onclick="transcribeLastRecording()">
                Send to Transcription
            </button>
        </div>
        
        <div class="status" id="status">Ready. Configure virtual audio cable as default input, then record when ready.</div>
    </div>

    <script>
        let mediaRecorder = null;
        let recordedChunks = [];
        let isRecording = false;
        let recordingStartTime = null;
        let recordingInterval = null;
        let lastRecordingPath = null;
        let audioContext = null;
        let inputAnalyser = null;
        let inputStream = null;
        
        // Initialize
        window.addEventListener('DOMContentLoaded', async () => {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            
            // Start audio level monitoring immediately  
            try {
                await startAudioMonitoring();
                updateStatus('Audio monitoring active. Record when ready.', 'success');
            } catch (error) {
                updateStatus('Click record button to enable audio monitoring', 'info');
            }
        });
        
        // Start audio monitoring automatically
        async function startAudioMonitoring() {
            try {
                // Resume AudioContext if suspended
                if (audioContext.state === 'suspended') {
                    await audioContext.resume();
                }
                
                // Get default audio input (user configures virtual cable as default)
                inputStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        echoCancellation: false,
                        noiseSuppression: false,
                        autoGainControl: false
                    }
                });
                
                const source = audioContext.createMediaStreamSource(inputStream);
                inputAnalyser = audioContext.createAnalyser();
                inputAnalyser.fftSize = 256;
                source.connect(inputAnalyser);
                
                monitorInputLevel();
                console.log('Audio level monitoring started');
            } catch (error) {
                console.error('Audio monitoring failed:', error);
                throw error;
            }
        }
        
        function monitorInputLevel() {
            if (!inputAnalyser) return;
            const dataArray = new Uint8Array(inputAnalyser.frequencyBinCount);
            inputAnalyser.getByteFrequencyData(dataArray);
            const average = dataArray.reduce((a, b) => a + b) / dataArray.length;
            const percentage = Math.min(100, (average / 128) * 100);
            document.getElementById('inputLevel').style.width = percentage + '%';
            requestAnimationFrame(monitorInputLevel);
        }
        
        // Recording functions
        async function toggleRecording() {
            if (!isRecording) {
                startRecording();
            } else {
                stopRecording();
            }
        }
        
        async function startRecording() {
            try {
                // Ensure audio monitoring is active
                if (!inputStream) {
                    await startAudioMonitoring();
                }
                
                mediaRecorder = new MediaRecorder(inputStream);
                recordedChunks = [];
                
                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        recordedChunks.push(event.data);
                    }
                };
                
                mediaRecorder.onstop = saveRecording;
                mediaRecorder.start();
                isRecording = true;
                recordingStartTime = Date.now();
                
                document.getElementById('recordBtn').textContent = 'Stop Recording';
                document.getElementById('recordBtn').classList.add('recording');
                document.getElementById('recordingIndicator').classList.add('active');
                
                recordingInterval = setInterval(updateRecordingTimer, 100);
                updateStatus('Recording started', 'success');
            } catch (error) {
                updateStatus('Error: ' + error.message, 'error');
            }
        }
        
        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
                isRecording = false;
                clearInterval(recordingInterval);
                
                document.getElementById('recordBtn').textContent = 'Start Recording';
                document.getElementById('recordBtn').classList.remove('recording');
                document.getElementById('recordingIndicator').classList.remove('active');
                
                updateStatus('Recording stopped', 'success');
            }
        }
        
        function updateRecordingTimer() {
            if (!recordingStartTime) return;
            const elapsed = Date.now() - recordingStartTime;
            const seconds = Math.floor(elapsed / 1000) % 60;
            const minutes = Math.floor(elapsed / 60000);
            document.getElementById('recordingTimer').textContent = 
                minutes.toString().padStart(2, '0') + ':' + seconds.toString().padStart(2, '0');
        }
        
        async function saveRecording() {
            const blob = new Blob(recordedChunks, { type: 'audio/webm' });
            const timestamp = new Date().toISOString().replace(/[:.]/g, '-').slice(0, -5);
            const filename = 'recording_' + timestamp + '.webm';
            
            // Create blob URL for immediate playback
            lastRecordingPath = URL.createObjectURL(blob);
            
            // Auto-download the file
            const downloadLink = document.createElement('a');
            downloadLink.href = lastRecordingPath;
            downloadLink.download = filename;
            downloadLink.style.display = 'none';
            document.body.appendChild(downloadLink);
            downloadLink.click();
            document.body.removeChild(downloadLink);
            
            updateStatus('Recording saved: ' + filename, 'success');
            window.lastRecordingBlob = blob;
        }
        
        // Playback
        async function playAudio() {
            const urlInput = document.getElementById('audioUrl').value;
            
            let audioUrl = urlInput;
            
            // If no URL provided, use last recording if available
            if (!audioUrl && lastRecordingPath) {
                audioUrl = lastRecordingPath;
                updateStatus('Playing last recording...', 'success');
            } else if (!audioUrl) {
                updateStatus('Please provide audio URL or record something first', 'error');
                return;
            }
            
            try {
                const audio = new Audio(audioUrl);
                audio.play();
                updateStatus('Playing audio...', 'success');
            } catch (error) {
                updateStatus('Error: ' + error.message, 'error');
            }
        }
        
        // Transcription
        async function transcribeLastRecording() {
            if (!window.lastRecordingBlob) {
                updateStatus('No recording to transcribe', 'error');
                return;
            }
            
            try {
                updateStatus('Sending to transcription...', 'info');
                const formData = new FormData();
                formData.append('audio', window.lastRecordingBlob, 'recording.webm');
                
                const response = await fetch('https://n8n.thegroundeffect.com/webhook/voice-chat-audio', {
                    method: 'POST',
                    body: formData
                });
                
                if (response.ok) {
                    updateStatus('Transcription sent successfully', 'success');
                } else {
                    updateStatus('Transcription failed: ' + response.statusText, 'error');
                }
            } catch (error) {
                updateStatus('Error: ' + error.message, 'error');
            }
        }
        
        function updateStatus(message, type = 'info') {
            const statusEl = document.getElementById('status');
            statusEl.textContent = message;
            statusEl.className = 'status';
            if (type === 'error' || type === 'success') {
                statusEl.classList.add(type);
            }
        }
    </script>
</body>
</html>