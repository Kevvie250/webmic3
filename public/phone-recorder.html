<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Audio Control Panel</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            height: 100vh;
            padding: 20px;
        }
        .container {
            max-width: 600px;
            margin: 0 auto;
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
            padding: 30px;
        }
        h1 {
            color: #333;
            margin-bottom: 30px;
            text-align: center;
        }
        .section {
            margin-bottom: 25px;
            padding: 20px;
            background: #f8f9fa;
            border-radius: 10px;
        }
        .section-title {
            font-size: 14px;
            font-weight: 600;
            color: #666;
            text-transform: uppercase;
            letter-spacing: 1px;
            margin-bottom: 15px;
        }
        .device-selector {
            display: flex;
            gap: 10px;
            align-items: center;
            margin-bottom: 10px;
        }
        select {
            flex: 1;
            padding: 10px;
            border: 2px solid #e0e0e0;
            border-radius: 8px;
            font-size: 14px;
            background: white;
        }
        .audio-meter {
            height: 30px;
            background: #e0e0e0;
            border-radius: 15px;
            overflow: hidden;
            position: relative;
            margin-bottom: 5px;
            border: 2px solid #ccc;
        }
        .audio-level {
            height: 100%;
            background: linear-gradient(90deg, #4ade80 0%, #fbbf24 70%, #ef4444 100%);
            border-radius: 15px;
            transition: width 0.1s ease-out;
            width: 0%;
        }
        .btn {
            width: 100%;
            padding: 15px;
            border: none;
            border-radius: 10px;
            font-size: 16px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s;
            text-transform: uppercase;
            letter-spacing: 1px;
            margin-top: 10px;
        }
        .btn-record {
            background: #ef4444;
            color: white;
        }
        .btn-record.recording {
            background: #991b1b;
            animation: pulse 1.5s infinite;
        }
        @keyframes pulse {
            0% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.7); }
            70% { box-shadow: 0 0 0 10px rgba(239, 68, 68, 0); }
            100% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0); }
        }
        .btn-play {
            background: #10b981;
            color: white;
        }
        .btn-transcribe {
            background: #8b5cf6;
            color: white;
        }
        .status {
            padding: 15px;
            background: #f0f9ff;
            border-left: 4px solid #3b82f6;
            border-radius: 5px;
            font-size: 14px;
            color: #1e40af;
            margin-top: 20px;
        }
        .status.error {
            background: #fef2f2;
            border-left-color: #ef4444;
            color: #991b1b;
        }
        .status.success {
            background: #f0fdf4;
            border-left-color: #10b981;
            color: #166534;
        }
        .status.warning {
            background: #fffbeb;
            border-left-color: #f59e0b;
            color: #92400e;
        }
        input[type="text"] {
            width: 100%;
            padding: 10px;
            border: 2px solid #e0e0e0;
            border-radius: 8px;
            font-size: 14px;
            margin-bottom: 10px;
        }
        .recording-indicator {
            display: none;
            align-items: center;
            gap: 10px;
            padding: 10px;
            background: #fee2e2;
            border-radius: 8px;
            margin-top: 15px;
        }
        .recording-indicator.active {
            display: flex;
        }
        .recording-dot {
            width: 12px;
            height: 12px;
            background: #ef4444;
            border-radius: 50%;
            animation: blink 1s infinite;
        }
        @keyframes blink {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.3; }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üéôÔ∏è Audio Control Panel</h1>
        
        <div class="section">
            <div class="section-title">Audio Input Level</div>
            <div style="font-size: 12px; color: #666; margin-bottom: 5px;">Make sure audio is flowing (use Windows audio settings to route through virtual cable):</div>
            <div class="audio-meter">
                <div class="audio-level" id="recordingLevel"></div>
            </div>
        </div>
        
        <div class="section">
            <div class="section-title">Recording</div>
            <button class="btn btn-record" id="recordBtn" onclick="toggleRecording()">
                Start Recording
            </button>
            <div class="recording-indicator" id="recordingIndicator">
                <div class="recording-dot"></div>
                <span>Recording...</span>
                <span id="recordingTimer">00:00</span>
            </div>
        </div>
        
        <div class="section">
            <div class="section-title">Playback</div>
            <input type="text" id="audioUrl" placeholder="Paste ElevenLabs URL (or leave empty to select file)">
            <button class="btn btn-play" onclick="playAudio()">Play Audio</button>
        </div>
        
        <div class="section">
            <div class="section-title">Transcription</div>
            <button class="btn btn-transcribe" onclick="transcribeLastRecording()">
                Send to Transcription
            </button>
        </div>
        
        <div class="status" id="status">Ready. Select your audio devices to begin.</div>
    </div>

    <script>
        let mediaRecorder = null;
        let recordedChunks = [];
        let isRecording = false;
        let recordingStartTime = null;
        let recordingInterval = null;
        let lastRecordingPath = null;
        let audioContext = null;
        let inputAnalyser = null;
        let inputStream = null;
        
        // Initialize
        window.addEventListener('DOMContentLoaded', async () => {
            if (!audioContext) {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
            }
            
            // Start audio level monitoring immediately  
            try {
                await startAudioMonitoring();
                updateStatus('Audio monitoring active. Record when ready.', 'success');
            } catch (error) {
                updateStatus('Click record button to start audio monitoring', 'info');
            }
        });
        
        // Request audio permissions to get device labels
        async function requestAudioPermissions() {
            try {
                // Request microphone access to get device labels
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: true,
                    video: false 
                });
                // Immediately stop the stream - we just needed permission
                stream.getTracks().forEach(track => track.stop());
                return true;
            } catch (error) {
                console.log('Permission request failed:', error);
                updateStatus('Please allow microphone access to see device names', 'warning');
                return false;
            }
        }
        
        // Refresh devices
        async function refreshDevices() {
            try {
                // Try to get permissions if we don't have them
                const hasPermission = await requestAudioPermissions();
                
                const devices = await navigator.mediaDevices.enumerateDevices();
                const recordingSelect = document.getElementById('recordingDevice');
                const playbackSelect = document.getElementById('playbackDevice');
                
                // Store current selections
                const currentRecording = recordingSelect.value;
                const currentPlayback = playbackSelect.value;
                
                recordingSelect.innerHTML = '<option value="">Select recording device...</option>';
                playbackSelect.innerHTML = '<option value="">Select playback device...</option>';
                
                // Add audio inputs (for recording)
                let inputCount = 0;
                devices.filter(d => d.kind === 'audioinput').forEach(device => {
                    const option = document.createElement('option');
                    option.value = device.deviceId;
                    
                    // Better device labeling
                    if (device.label) {
                        option.textContent = device.label;
                        // Highlight virtual cables
                        if (device.label.toLowerCase().includes('cable') || 
                            device.label.toLowerCase().includes('virtual')) {
                            option.textContent = 'üîå ' + device.label;
                        }
                    } else {
                        option.textContent = `Microphone ${++inputCount}`;
                    }
                    
                    recordingSelect.appendChild(option);
                });
                
                // Add audio outputs (for playback)
                let outputCount = 0;
                devices.filter(d => d.kind === 'audiooutput').forEach(device => {
                    const option = document.createElement('option');
                    option.value = device.deviceId;
                    
                    // Better device labeling
                    if (device.label) {
                        option.textContent = device.label;
                        // Highlight virtual cables
                        if (device.label.toLowerCase().includes('cable') || 
                            device.label.toLowerCase().includes('virtual')) {
                            option.textContent = 'üîå ' + device.label;
                        }
                    } else {
                        option.textContent = `Speaker ${++outputCount}`;
                    }
                    
                    playbackSelect.appendChild(option);
                });
                
                // Restore selections if they still exist
                if (currentRecording) recordingSelect.value = currentRecording;
                if (currentPlayback) playbackSelect.value = currentPlayback;
                
                // Show helpful message if no virtual cables found
                const hasCables = Array.from(recordingSelect.options).some(opt => 
                    opt.textContent.includes('üîå'));
                
                if (!hasCables && hasPermission) {
                    updateStatus('No virtual cables detected. Install VB-Cable or Virtual Audio Cable.', 'warning');
                } else if (hasCables) {
                    updateStatus('Devices refreshed. Virtual cables detected!', 'success');
                } else {
                    updateStatus('Devices refreshed', 'success');
                }
                
            } catch (error) {
                updateStatus('Error: ' + error.message, 'error');
            }
        }
        
        // Monitor input levels
        document.getElementById('recordingDevice').addEventListener('change', async (e) => {
            const deviceId = e.target.value;
            if (!deviceId) return;
            
            try {
                // Resume AudioContext if suspended (browser security requirement)
                if (audioContext.state === 'suspended') {
                    await audioContext.resume();
                }
                
                if (inputStream) {
                    inputStream.getTracks().forEach(track => track.stop());
                }
                
                console.log('Requesting audio access for device:', deviceId);
                inputStream = await navigator.mediaDevices.getUserMedia({
                    audio: { 
                        deviceId: { exact: deviceId },
                        echoCancellation: false,
                        noiseSuppression: false,
                        autoGainControl: false
                    }
                });
                
                console.log('Audio stream acquired, setting up monitoring');
                const source = audioContext.createMediaStreamSource(inputStream);
                inputAnalyser = audioContext.createAnalyser();
                inputAnalyser.fftSize = 256;
                source.connect(inputAnalyser);
                
                monitorInputLevel();
                
                // Show device name in status
                const deviceLabel = e.target.options[e.target.selectedIndex].text;
                updateStatus(`Connected to: ${deviceLabel} - Level monitoring active`, 'success');
                console.log('Audio level monitoring started');
                
                // Save settings to localStorage
                localStorage.setItem('audioSettings', JSON.stringify({
                    recordingDevice: deviceId,
                    playbackDevice: document.getElementById('playbackDevice').value
                }));
            } catch (error) {
                console.error('Audio setup failed:', error);
                updateStatus('Audio setup failed: ' + error.message, 'error');
            }
        });
        
        function monitorInputLevel() {
            if (!inputAnalyser) return;
            const dataArray = new Uint8Array(inputAnalyser.frequencyBinCount);
            inputAnalyser.getByteFrequencyData(dataArray);
            const average = dataArray.reduce((a, b) => a + b) / dataArray.length;
            const percentage = Math.min(100, (average / 128) * 100);
            document.getElementById('recordingLevel').style.width = percentage + '%';
            requestAnimationFrame(monitorInputLevel);
        }
        
        // Recording functions
        async function toggleRecording() {
            if (!isRecording) {
                startRecording();
            } else {
                stopRecording();
            }
        }
        
        async function startRecording() {
            const deviceId = document.getElementById('recordingDevice').value;
            if (!deviceId) {
                updateStatus('Please select a recording device', 'error');
                return;
            }
            
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    audio: { 
                        deviceId: { exact: deviceId },
                        echoCancellation: false,
                        noiseSuppression: false,
                        autoGainControl: false
                    }
                });
                
                mediaRecorder = new MediaRecorder(stream);
                recordedChunks = [];
                
                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        recordedChunks.push(event.data);
                    }
                };
                
                mediaRecorder.onstop = saveRecording;
                mediaRecorder.start();
                isRecording = true;
                recordingStartTime = Date.now();
                
                document.getElementById('recordBtn').textContent = 'Stop Recording';
                document.getElementById('recordBtn').classList.add('recording');
                document.getElementById('recordingIndicator').classList.add('active');
                
                recordingInterval = setInterval(updateRecordingTimer, 100);
                updateStatus('Recording started', 'success');
            } catch (error) {
                updateStatus('Error: ' + error.message, 'error');
            }
        }
        
        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
                mediaRecorder.stream.getTracks().forEach(track => track.stop());
                isRecording = false;
                clearInterval(recordingInterval);
                
                document.getElementById('recordBtn').textContent = 'Start Recording';
                document.getElementById('recordBtn').classList.remove('recording');
                document.getElementById('recordingIndicator').classList.remove('active');
                
                updateStatus('Recording stopped', 'success');
            }
        }
        
        function updateRecordingTimer() {
            if (!recordingStartTime) return;
            const elapsed = Date.now() - recordingStartTime;
            const seconds = Math.floor(elapsed / 1000) % 60;
            const minutes = Math.floor(elapsed / 60000);
            document.getElementById('recordingTimer').textContent = 
                minutes.toString().padStart(2, '0') + ':' + seconds.toString().padStart(2, '0');
        }
        
        async function saveRecording() {
            const blob = new Blob(recordedChunks, { type: 'audio/webm' });
            const timestamp = new Date().toISOString().replace(/[:.]/g, '-').slice(0, -5);
            const filename = 'recording_' + timestamp + '.webm';
            
            // Create blob URL for immediate playback
            lastRecordingPath = URL.createObjectURL(blob);
            updateStatus('Recording ready: ' + filename, 'success');
            
            window.lastRecordingBlob = blob;
        }
        
        // Playback
        async function playAudio() {
            const urlInput = document.getElementById('audioUrl').value;
            const deviceId = document.getElementById('playbackDevice').value;
            
            if (!deviceId) {
                updateStatus('Please select a playback device', 'error');
                return;
            }
            
            try {
                let audioUrl = urlInput;
                
                // If no URL provided, use last recording if available
                if (!audioUrl && lastRecordingPath) {
                    audioUrl = lastRecordingPath;
                    updateStatus('Playing last recording...', 'success');
                } else if (!audioUrl) {
                    updateStatus('Please provide audio URL or record something first', 'error');
                    return;
                }
                
                if (audioUrl) {
                    const audio = new Audio(audioUrl);
                    if (audio.setSinkId) {
                        await audio.setSinkId(deviceId);
                    }
                    audio.play();
                    updateStatus('Playing audio...', 'success');
                    
                    // Simple level visualization
                    audio.addEventListener('play', () => {
                        const interval = setInterval(() => {
                            if (audio.paused || audio.ended) {
                                clearInterval(interval);
                                document.getElementById('playbackLevel').style.width = '0%';
                            } else {
                                const level = 30 + Math.random() * 40;
                                document.getElementById('playbackLevel').style.width = level + '%';
                            }
                        }, 100);
                    });
                }
            } catch (error) {
                updateStatus('Error: ' + error.message, 'error');
            }
        }
        
        // Transcription
        async function transcribeLastRecording() {
            if (!window.lastRecordingBlob) {
                updateStatus('No recording to transcribe', 'error');
                return;
            }
            
            try {
                updateStatus('Sending to transcription...', 'info');
                const formData = new FormData();
                formData.append('audio', window.lastRecordingBlob, 'recording.webm');
                
                const response = await fetch('https://n8n.thegroundeffect.com/webhook/voice-chat-audio', {
                    method: 'POST',
                    body: formData
                });
                
                if (response.ok) {
                    updateStatus('Transcription sent successfully', 'success');
                } else {
                    updateStatus('Transcription failed: ' + response.statusText, 'error');
                }
            } catch (error) {
                updateStatus('Error: ' + error.message, 'error');
            }
        }
        
        function updateStatus(message, type = 'info') {
            const statusEl = document.getElementById('status');
            statusEl.textContent = message;
            statusEl.className = 'status';
            if (type === 'error' || type === 'success' || type === 'warning') {
                statusEl.classList.add(type);
            }
        }
    </script>
</body>
</html>
